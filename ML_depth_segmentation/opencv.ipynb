{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "\n",
    "# termination criteria\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "\n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((5*5,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:5,0:5].T.reshape(-1,2)\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d point in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "images = glob.glob('cv/*.jpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fname in images:\n",
    "    img = cv2.imread(fname)\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find the chess board corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (5,5),None)\n",
    "\n",
    "    # If found, add object points, image points (after refining them)\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "\n",
    "        corners2 = cv2.cornerSubPix(gray,corners,(11,11),(-1,-1),criteria)\n",
    "        imgpoints.append(corners2)\n",
    "\n",
    "        # Draw and display the corners\n",
    "        img = cv2.drawChessboardCorners(img, (5,5), corners2,ret)\n",
    "        cv2.imshow('img',img)\n",
    "        cv2.waitKey(500)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibration\n",
    "So now we have our object points and image points we are ready to go for calibration. For that we use the function, cv2.calibrateCamera(). It returns the camera matrix, distortion coefficients, rotation and translation vectors etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1],None,None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Undistortion\n",
    "We have got what we were trying. Now we can take an image and undistort it. OpenCV comes with two methods, we will see both. But before that, we can refine the camera matrix based on a free scaling parameter using cv2.getOptimalNewCameraMatrix(). If the scaling parameter alpha=0, it returns undistorted image with minimum unwanted pixels. So it may even remove some pixels at image corners. If alpha=1, all pixels are retained with some extra black images. It also returns an image ROI which can be used to crop the result.\n",
    "\n",
    "So we take a new image (left12.jpg in this case. That is the first image in this chapter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('cv/test1.jpg')\n",
    "h,  w = img.shape[:2]\n",
    "newcameramtx, roi=cv2.getOptimalNewCameraMatrix(mtx,dist,(w,h),1,(w,h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# undistort\n",
    "dst = cv2.undistort(img, mtx, dist, None, newcameramtx)\n",
    "\n",
    "# crop the image\n",
    "x,y,w,h = roi\n",
    "dst = dst[y:y+h, x:x+w]\n",
    "cv2.imwrite('cv/calibresult.png',dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# undistort\n",
    "mapx,mapy = cv2.initUndistortRectifyMap(mtx,dist,None,newcameramtx,(w,h),5)\n",
    "dst = cv2.remap(img,mapx,mapy,cv2.INTER_LINEAR)\n",
    "\n",
    "# crop the image\n",
    "x,y,w,h = roi\n",
    "dst = dst[y:y+h, x:x+w]\n",
    "cv2.imwrite('calibresult.png',dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(867, 636)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapx.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-projection Error\n",
    "Re-projection error gives a good estimation of just how exact is the found parameters. This should be as close to zero as possible. Given the intrinsic, distortion, rotation and translation matrices, we first transform the object point to image point using cv2.projectPoints(). Then we calculate the absolute norm between what we got with our transformation and the corner finding algorithm. To find the average error we calculate the arithmetical mean of the errors calculate for all the calibration images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total error:  0.25709820340049283\n"
     ]
    }
   ],
   "source": [
    "tot_error = 0\n",
    "for i in range(len(objpoints)):\n",
    "    imgpoints2, _ = cv2.projectPoints(objpoints[i], rvecs[i], tvecs[i], mtx, dist)\n",
    "    error = cv2.norm(imgpoints[i],imgpoints2, cv2.NORM_L2)/len(imgpoints2)\n",
    "    tot_error += error\n",
    "\n",
    "print(\"total error: \", tot_error/len(objpoints))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pose Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw(img, corners, imgpts):\n",
    "    corner = tuple(corners[0].ravel())\n",
    "    img = cv2.line(img, corner, tuple(imgpts[0].ravel()), (255,0,0), 5)\n",
    "    img = cv2.line(img, corner, tuple(imgpts[1].ravel()), (0,255,0), 5)\n",
    "    img = cv2.line(img, corner, tuple(imgpts[2].ravel()), (0,0,255), 5)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "objp = np.zeros((5*5,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:5,0:5].T.reshape(-1,2)\n",
    "\n",
    "axis = np.float32([[3,0,0], [0,3,0], [0,0,-3]]).reshape(-1,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, as usual, we load each image. Search for 7x6 grid. If found, we refine it with subcorner pixels. Then to calculate the rotation and translation, we use the function, cv2.solvePnPRansac(). Once we those transformation matrices, we use them to project our axis points to the image plane. In simple words, we find the points on image plane corresponding to each of (3,0,0),(0,3,0),(0,0,3) in 3D space. Once we get them, we draw lines from the first corner to each of these points using our draw() function. Done !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = glob.glob('cv/c*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fname in images:\n",
    "    img = cv2.imread(fname)\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (5,5),None)\n",
    "\n",
    "    if ret == True:\n",
    "        corners2 = cv2.cornerSubPix(gray,corners,(11,11),(-1,-1),criteria)\n",
    "\n",
    "        # Find the rotation and translation vectors.\n",
    "        _, rvecs, tvecs, inliers = cv2.solvePnPRansac(objp, corners2, mtx, dist)\n",
    "\n",
    "        # project 3D points to image plane\n",
    "        imgpts, jac = cv2.projectPoints(axis, rvecs, tvecs, mtx, dist)\n",
    "\n",
    "        img = draw(img,corners2,imgpts)\n",
    "        cv2.imshow('img',img)\n",
    "        k = cv2.waitKey(0) & 0xff\n",
    "        if k == 's':\n",
    "            cv2.imwrite(fname[:6]+'.png', img)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 1, 2)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corners2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, rvecs, tvecs, inliers = cv2.solvePnPRansac(objp, corners2, mtx, dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Render a Cube\n",
    "If you want to draw a cube, modify the draw() function and axis points as follows.\n",
    "\n",
    "Modified draw() function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw(img, corners, imgpts):\n",
    "    imgpts = np.int32(imgpts).reshape(-1,2)\n",
    "\n",
    "    # draw ground floor in green\n",
    "    img = cv2.drawContours(img, [imgpts[:4]],-1,(0,255,0),-3)\n",
    "\n",
    "    # draw pillars in blue color\n",
    "    for i,j in zip(range(4),range(4,8)):\n",
    "        img = cv2.line(img, tuple(imgpts[i]), tuple(imgpts[j]),(255),3)\n",
    "\n",
    "    # draw top layer in red color\n",
    "    img = cv2.drawContours(img, [imgpts[4:]],-1,(0,0,255),3)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "axis = np.float32([[0,0,0], [0,3,0], [3,3,0], [3,0,0],\n",
    "                   [0,0,-3],[0,3,-3],[3,3,-3],[3,0,-3] ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try to get camera pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trans_matrix(r,t):\n",
    "    # T (ki to t), rotate and transport matrix\n",
    "    (a,b,c) = (r[0][0], r[1][0], r[2][0])\n",
    "    (x,y,z) = (t[0][0],t[1][0],t[2][0])\n",
    "    Rz = np.matrix([[1,0,0],\n",
    "          [0, np.cos(a), -np.sin(a)],\n",
    "         [0, np.sin(a), np.cos(a)]])\n",
    "    Ry = np.matrix([[np.cos(b), 0 , np.sin(b)],\n",
    "          [0 , 1, 0],\n",
    "          [-np.sin(b), 0 , np.cos(b)]])\n",
    "    Rx = np.matrix([[np.cos(c), -np.sin(c), 0],\n",
    "         [np.sin(c), np.cos(c), 0],\n",
    "         [0,0,1]])\n",
    "    R = np.dot(Rz,np.dot(Ry,Rx))\n",
    "    T = np.concatenate((R, np.matrix([[x],[y],[z]])), axis=1)\n",
    "    \n",
    "    return T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pi_trans(x,l):\n",
    "    u = np.zeros((l,2))\n",
    "    for i in range(l):\n",
    "        u[i,0] = x[0,i]/x[2,i]\n",
    "        u[i,1] = x[1,i]/x[2,i]\n",
    "    return u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "rvecs_set = []\n",
    "tvecs_set = []\n",
    "\n",
    "fname = 'cv/test1.jpg'\n",
    "img = cv2.imread(fname)\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "ret, corners = cv2.findChessboardCorners(gray, (5,5),None)\n",
    "\n",
    "if ret == True:\n",
    "    corners2 = cv2.cornerSubPix(gray,corners,(11,11),(-1,-1),criteria)\n",
    "\n",
    "    # Find the rotation and translation vectors.\n",
    "    _, rvecs, tvecs, inliers = cv2.solvePnPRansac(objp, corners2, mtx, dist)\n",
    "\n",
    "    # project 3D points to image plane\n",
    "    imgpts, jac = cv2.projectPoints(axis, rvecs, tvecs, mtx, dist)\n",
    "        \n",
    "    rvecs_set.append(rvecs)\n",
    "    tvecs_set.append(tvecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.],\n",
       "       [ 0.,  3.,  0.],\n",
       "       [ 3.,  3.,  0.],\n",
       "       [ 3.,  0.,  0.],\n",
       "       [ 0.,  0., -3.],\n",
       "       [ 0.,  3., -3.],\n",
       "       [ 3.,  3., -3.],\n",
       "       [ 3.,  0., -3.]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "axis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### transport matrix\n",
    "\n",
    "transposr from axis_cube to the cube in the image\n",
    "\n",
    "T_origin_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 9.85295221e-01,  1.20368386e-01, -1.21263263e-01,\n",
       "         -1.12759475e+00],\n",
       "        [-1.70786660e-01,  7.14693866e-01, -6.78265873e-01,\n",
       "         -3.48967636e+00],\n",
       "        [ 5.02434150e-03,  6.89002271e-01,  7.24741765e-01,\n",
       "          1.09166041e+01]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T = trans_matrix(rvecs_set[0], tvecs_set[0])\n",
    "T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "cube = np.concatenate((axis.T, [[1,1,1,1,1,1,1,1]]), axis=0)\n",
    "temp = np.dot(mtx, np.dot(T, cube))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[-3.33066907e-16, -1.66533454e-16,  3.00000000e+00,\n",
       "          3.00000000e+00, -2.22044605e-16,  0.00000000e+00,\n",
       "          3.00000000e+00,  3.00000000e+00],\n",
       "        [ 8.88178420e-16,  3.00000000e+00,  3.00000000e+00,\n",
       "          0.00000000e+00,  8.88178420e-16,  3.00000000e+00,\n",
       "          3.00000000e+00,  0.00000000e+00],\n",
       "        [ 1.77635684e-15,  1.77635684e-15,  1.77635684e-15,\n",
       "          0.00000000e+00, -3.00000000e+00, -3.00000000e+00,\n",
       "         -3.00000000e+00, -3.00000000e+00],\n",
       "        [ 1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "          1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "          1.00000000e+00,  1.00000000e+00]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T1 = np.concatenate((T, np.array([[0,0,0,1]])), axis=0)\n",
    "T0 = np.linalg.inv(T1)\n",
    "np.dot(T0,np.dot(T1,cube))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temp: [[322.93538373 196.69689097]\n",
      " [359.55767556 374.21029025]\n",
      " [547.78684345 341.92022197]\n",
      " [546.80619917 158.54604515]\n",
      " [336.11217898 322.62418871]\n",
      " [377.58105411 511.76281309]\n",
      " [603.59326194 472.79534702]\n",
      " [615.54104805 274.78483516]]\n",
      "imgpts: [[[326.26077 195.00955]]\n",
      "\n",
      " [[183.65842 361.10806]]\n",
      "\n",
      " [[338.9686  500.62103]]\n",
      "\n",
      " [[485.4027  350.217  ]]\n",
      "\n",
      " [[303.63016 179.38838]]\n",
      "\n",
      " [[117.29534 401.15668]]\n",
      "\n",
      " [[324.29642 582.23126]]\n",
      "\n",
      " [[518.2971  387.90305]]]\n"
     ]
    }
   ],
   "source": [
    "cube = np.concatenate((axis.T, [[1,1,1,1,1,1,1,1]]), axis=0)\n",
    "temp = np.dot(mtx, np.dot(T, cube))\n",
    "temp = pi_trans(temp,8)\n",
    "print('temp:',temp)\n",
    "print('imgpts:', imgpts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python 3.5 tf gpu",
   "language": "python",
   "name": "tensorflow_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
